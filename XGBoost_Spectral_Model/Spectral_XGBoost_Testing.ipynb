{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference using ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Installation\n",
    "\n",
    "This project relies on the following major dependencies:\n",
    "\n",
    "- [**Python**](https://www.python.org/downloads/): The primary programming language used. We're using the latest Python3\n",
    "- [**Jupyter Notebook**](https://jupyter.org/install): Handles the .ipynb format file execution.\n",
    "- [**VSCode**](https://code.visualstudio.com/): Code editor and simple notebook environment.\n",
    "- **Libraries**: \n",
    "  - `opencv-python`: For image processing and computer vision tasks.\n",
    "  - `numpy`: Essential for numerical operations.\n",
    "  - `onnxruntime`: Execute ONNX binaries.\n",
    "\n",
    "Easy Jupyter Notebook installation (with Python3 already installed):\n",
    "- Open this file in [VSCode](https://code.visualstudio.com/) and use extensions (VSCode will prompt you) to configure and run the python and jupyter env."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies:\n",
    "\n",
    "#### In your command prompt with Python 3 installed, type:\n",
    "`pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy for numerical operations\n",
    "import numpy as np\n",
    "# Import ONNX runtime to run the inference\n",
    "import onnxruntime as rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model in a session from file\n",
    "sess = rt.InferenceSession(\"./fishazam-xgboost-classifier-spectrum.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "# Or from bytes\n",
    "#sess = rt.InferenceSession(model_onnx.SerializeToString(), providers=[\"CPUExecutionProvider\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load spectrum data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"./content/alaskanhalibut_200wdaylight_frozen.csv\", delimiter=',')\n",
    "\n",
    "# Flatten image and add one axis representing one image in batch, skip header\n",
    "flat = data[1:].flatten()\n",
    "flat = flat[np.newaxis, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict [1]\n",
      "predict_proba [[0.08574136 0.36749336 0.08583967 0.1182318  0.14002253 0.08587299\n",
      "  0.11679839]]\n"
     ]
    }
   ],
   "source": [
    "pred_onx = sess.run(None, {\"input\": flat.astype(np.float32)})\n",
    "print(\"predict\", pred_onx[0]) # 1 is alaskanhalibut\n",
    "print(\"predict_proba\", pred_onx[1][:1]) # Print predicted probabilities for all classes"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
